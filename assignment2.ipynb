{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2019d856",
   "metadata": {},
   "source": [
    "# Predicting Rate my Professor Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7070fec0",
   "metadata": {},
   "source": [
    "### Identifying the predictive Task \n",
    "\n",
    "In this project we will analyze a dataset of user's rate my professor ratings and predict what rating a user will give to a certain professor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "695b5fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting numpy>=1.17 (from datasets)\n",
      "  Downloading numpy-2.3.5-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.2 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting httpx<1.0.0 (from datasets)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "Collecting fsspec<=2025.10.0,>=2023.1.0 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting huggingface-hub<2.0,>=0.25.0 (from datasets)\n",
      "  Downloading huggingface_hub-1.1.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /Users/luisxu/Documents/cse158/.conda/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Collecting pyyaml>=5.1 (from datasets)\n",
      "  Downloading pyyaml-6.0.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.13.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Collecting anyio (from httpx<1.0.0->datasets)\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting certifi (from httpx<1.0.0->datasets)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1.0.0->datasets)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting shellingham (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/luisxu/Documents/cse158/.conda/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.7.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.22.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1.0.0->datasets)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/luisxu/Documents/cse158/.conda/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/luisxu/Documents/cse158/.conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting click>=8.0.0 (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading huggingface_hub-1.1.5-py3-none-any.whl (516 kB)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
      "Downloading aiohttp-3.13.2-cp312-cp312-macosx_11_0_arm64.whl (491 kB)\n",
      "Downloading multidict-6.7.0-cp312-cp312-macosx_11_0_arm64.whl (43 kB)\n",
      "Downloading yarl-1.22.0-cp312-cp312-macosx_11_0_arm64.whl (94 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-macosx_11_0_arm64.whl (50 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading numpy-2.3.5-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.4.1-cp312-cp312-macosx_11_0_arm64.whl (47 kB)\n",
      "Downloading pyarrow-22.0.0-cp312-cp312-macosx_12_0_arm64.whl (34.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.2/34.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pyyaml-6.0.3-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl (208 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading pandas-2.3.3-cp312-cp312-macosx_11_0_arm64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading xxhash-3.6.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
      "Installing collected packages: pytz, xxhash, urllib3, tzdata, tqdm, sniffio, shellingham, pyyaml, pyarrow, propcache, numpy, multidict, idna, hf-xet, h11, fsspec, frozenlist, filelock, dill, click, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, typer-slim, requests, pandas, multiprocess, httpcore, anyio, aiosignal, httpx, aiohttp, huggingface-hub, datasets\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36/36\u001b[0m [datasets]/36\u001b[0m [datasets]ce-hub]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 anyio-4.11.0 attrs-25.4.0 certifi-2025.11.12 charset_normalizer-3.4.4 click-8.3.1 datasets-4.4.1 dill-0.4.0 filelock-3.20.0 frozenlist-1.8.0 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-1.1.5 idna-3.11 multidict-6.7.0 multiprocess-0.70.18 numpy-2.3.5 pandas-2.3.3 propcache-0.4.1 pyarrow-22.0.0 pytz-2025.2 pyyaml-6.0.3 requests-2.32.5 shellingham-1.5.4 sniffio-1.3.1 tqdm-4.67.1 typer-slim-0.20.0 tzdata-2025.2 urllib3-2.5.0 xxhash-3.6.0 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e982f75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisxu/Documents/cse158/.conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"ZephyrUtopia/ratemyprofessors_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c86965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = ds[\"train\"].to_pandas()\n",
    "df_test = ds[\"test\"].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda9d2ec",
   "metadata": {},
   "source": [
    "### Exploratory Analysis, Data Collection, Preprocessing, and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4a8ed9",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bed33086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def MSE(y, ypred):\n",
    "    y = np.array(y, dtype=float)\n",
    "    ypred = np.array(ypred, dtype=float)\n",
    "    return np.mean((y - ypred) ** 2)\n",
    "\n",
    "def getGlobalAverage(trainRatings):\n",
    "    # Return the average rating in the training set\n",
    "    return np.mean(trainRatings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7133f06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leila Hawana</td>\n",
       "      <td>Although the homework is not too much, they ar...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gloria Magana</td>\n",
       "      <td>Where can I start she's a very tough grader. H...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-12-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Teresa Canganelli</td>\n",
       "      <td>She is a wonderful professor! Very interactive...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-02-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kumar Ankit</td>\n",
       "      <td>Study solutions had incorrect answers taken fr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Irina Garces</td>\n",
       "      <td>Super nice and helpful. Was always there in of...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-05-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336234</th>\n",
       "      <td>Ruth Chananie</td>\n",
       "      <td>Great professor, weekly discussions. Great wri...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2021-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336235</th>\n",
       "      <td>Jennifer Baggett</td>\n",
       "      <td>She is an amazing teacher and a great person t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336236</th>\n",
       "      <td>JoAnn Balingit</td>\n",
       "      <td>Really fun professor! Her class is super inter...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-10-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336237</th>\n",
       "      <td>Jacobson Blomquist</td>\n",
       "      <td>This professor holds the textbook and reads ou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336238</th>\n",
       "      <td>Shuhebur Rahman</td>\n",
       "      <td>He makes class very interesting and you always...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-12-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336239 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name                                               text  \\\n",
       "0             Leila Hawana  Although the homework is not too much, they ar...   \n",
       "1            Gloria Magana  Where can I start she's a very tough grader. H...   \n",
       "2        Teresa Canganelli  She is a wonderful professor! Very interactive...   \n",
       "3              Kumar Ankit  Study solutions had incorrect answers taken fr...   \n",
       "4             Irina Garces  Super nice and helpful. Was always there in of...   \n",
       "...                    ...                                                ...   \n",
       "336234       Ruth Chananie  Great professor, weekly discussions. Great wri...   \n",
       "336235    Jennifer Baggett  She is an amazing teacher and a great person t...   \n",
       "336236      JoAnn Balingit  Really fun professor! Her class is super inter...   \n",
       "336237  Jacobson Blomquist  This professor holds the textbook and reads ou...   \n",
       "336238     Shuhebur Rahman  He makes class very interesting and you always...   \n",
       "\n",
       "       rating difficulty       date  \n",
       "0         4.0        5.0 2018-11-01  \n",
       "1         1.0        5.0 2020-12-15  \n",
       "2         5.0        4.0 2020-02-20  \n",
       "3         1.0        4.0 2018-12-11  \n",
       "4         5.0        4.0 2019-05-15  \n",
       "...       ...        ...        ...  \n",
       "336234    5.0        3.0 2021-12-12  \n",
       "336235    5.0        2.0 2021-05-20  \n",
       "336236    5.0        2.0 2018-10-31  \n",
       "336237    1.0        4.0 2018-12-11  \n",
       "336238    5.0        3.0 2022-12-15  \n",
       "\n",
       "[336239 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51c5b9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7674704600001783\n"
     ]
    }
   ],
   "source": [
    "train_ratings = np.array(df_train['rating'], dtype='float')\n",
    "test_ratings = np.array(df_test['rating'], dtype='float')\n",
    "print(getGlobalAverage(train_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6b4c749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4709575975729883\n"
     ]
    }
   ],
   "source": [
    "print(MSE(train_ratings, getGlobalAverage(train_ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0ddb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(26056) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/luisxu/Documents/cse158/.conda/lib/python3.12/site-packages (from scikit-learn) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/luisxu/Documents/cse158/.conda/lib/python3.12/site-packages (from scikit-learn) (1.16.3)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/luisxu/Documents/cse158/.conda/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Using cached scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a033924",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n\u001b[32m      3\u001b[39m df_train[\u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(df_train[\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      4\u001b[39m df_train[\u001b[33m\"\u001b[39m\u001b[33myear\u001b[39m\u001b[33m\"\u001b[39m] = df_train[\u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m].dt.year\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df_train[\"timestamp\"] = pd.to_datetime(df_train[\"date\"])\n",
    "df_train[\"year\"] = df_train[\"timestamp\"].dt.year\n",
    "df_train[\"month\"] = df_train[\"timestamp\"].dt.month\n",
    "df_train[\"dayofweek\"] = df_train[\"timestamp\"].dt.dayofweek\n",
    "df_train[\"day\"] = df_train[\"timestamp\"].dt.day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a276ac6",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126e93e1",
   "metadata": {},
   "source": [
    "### Discussion of Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b3569",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
